import typer
from rich.console import Console
from dotenv import load_dotenv
from ai_pentest.llm.factory import create_llm
from ai_pentest.core.agent import PentestContext
from ai_pentest.core.planner import SupervisorAgent
from ai_pentest.agents.recon import ReconAgent
from ai_pentest.agents.attack_surface_agent import AttackSurfaceAgent
from ai_pentest.agents.vuln_analysis import VulnAnalysisAgent
from ai_pentest.agents.reasoning_agent import ReasoningAgent
from ai_pentest.agents.exploitability_agent import ExploitabilityAgent
from ai_pentest.agents.risk_agent import RiskAgent
from ai_pentest.agents.attack_simulation import AttackSimulationAgent
from ai_pentest.agents.memory_agent import MemoryAgent
from ai_pentest.agents.report_agent import ReportAgent

load_dotenv()
console = Console()
app = typer.Typer(name="cortexsec", help="CortexSec - Autonomous AI Security Assessment Agent")


@app.command()
def start(
    target: str = typer.Option(..., "--target", "-t", help="Target URL or IP"),
    mode: str = typer.Option("lab", "--mode", "-m", help="Assessment mode (lab/authorized)"),
    provider: str = typer.Option("openai", "--provider", help="LLM provider: openai/claude/gemini"),
    model: str = typer.Option("", "--model", help="LLM model name (optional)"),
    api_key: str = typer.Option(None, "--api-key", help="LLM API Key"),
    max_cycles: int = typer.Option(5, "--max-cycles", help="Maximum autonomous reasoning cycles"),
    confidence_threshold: float = typer.Option(0.8, "--confidence-threshold", help="Stop when avg finding confidence reaches this"),
    coverage_threshold: float = typer.Option(0.8, "--coverage-threshold", help="Stop when coverage score reaches this"),
    causal_threshold: float = typer.Option(1.0, "--causal-threshold", help="Stop when attack-graph causal completeness reaches this"),
    min_stable_cycles: int = typer.Option(1, "--min-stable-cycles", help="Require this many cycles with no new findings before stopping"),
):
    """Start a fully autonomous security assessment."""
    console.print(f"[bold blue]Starting AI Security Assessment for:[/bold blue] {target}")
    console.print(f"[bold yellow]Mode:[/bold yellow] {mode}")

    if mode == "lab" and not (target.startswith("http://localhost") or "127.0.0.1" in target):
        console.print("[bold red]Error: Lab mode only supports localhost targets.[/bold red]")
        raise typer.Exit(code=1)

    llm = create_llm(provider=provider, model=model, api_key=api_key)

    agents = [
        ReconAgent(llm),
        AttackSurfaceAgent(llm),
        VulnAnalysisAgent(llm),
        ReasoningAgent(llm),
        ExploitabilityAgent(llm),
        RiskAgent(llm),
        AttackSimulationAgent(llm),
        MemoryAgent(llm),
        ReportAgent(llm),
    ]

    supervisor = SupervisorAgent(
        llm,
        agents,
        max_cycles=max_cycles,
        confidence_threshold=confidence_threshold,
        coverage_threshold=coverage_threshold,
        causal_threshold=causal_threshold,
        min_stable_cycles=min_stable_cycles,
    )

    context = PentestContext(target=target, mode=mode)
    final_context = supervisor.run(context)

    console.print("\n[bold green]Assessment Complete![/bold green]")
    console.print(f"Total Findings: {len(final_context.findings)}")
    console.print(f"Risk Level: {final_context.risk_summary.get('level', 'Unknown')}")
    console.print(f"Coverage Score: {final_context.assessment_metrics.get('coverage_score', 0.0)}")
    console.print(f"Average Confidence: {final_context.assessment_metrics.get('avg_confidence', 0.0)}")
    console.print(f"Causal Completeness: {final_context.assessment_metrics.get('causal_completeness', 0.0)}")
    console.print(
        f"Reachable Findings Analyzed: "
        f"{final_context.assessment_metrics.get('analyzed_reachable_findings', 0)}/"
        f"{final_context.assessment_metrics.get('reachable_findings', 0)}"
    )
    console.print(f"Stop Reason: {final_context.stop_reason}")
    console.print("Check the 'reports' directory for the final report.")


if __name__ == "__main__":
    app()
