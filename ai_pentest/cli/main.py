import typer
from rich.console import Console
from ai_pentest.llm.openai import OpenAILLM
from ai_pentest.core.agent import PentestContext
from ai_pentest.core.planner import SupervisorAgent
from ai_pentest.agents.recon import ReconAgent
from ai_pentest.agents.vuln_analysis import VulnAnalysisAgent
from ai_pentest.agents.report_agent import ReportAgent
import os
from dotenv import load_dotenv

load_dotenv()
console = Console()
app = typer.Typer(name="cortexsec", help="CortexSec - Autonomous AI Security Assessment Agent")

@app.command()
def start(
    target: str = typer.Option(..., "--target", "-t", help="Target URL or IP"),
    mode: str = typer.Option("lab", "--mode", "-m", help="Assessment mode (lab/authorized)"),
    api_key: str = typer.Option(None, "--api-key", help="LLM API Key")
):
    """
    Start an autonomous security assessment.
    """
    console.print(f"[bold blue]Starting AI Security Assessment for:[/bold blue] {target}")
    console.print(f"[bold yellow]Mode:[/bold yellow] {mode}")
    
    if mode == "lab" and not (target.startswith("http://localhost") or "127.0.0.1" in target):
        console.print("[bold red]Error: Lab mode only supports localhost targets.[/bold red]")
        raise typer.Exit(code=1)

    # Initialize LLM
    llm = OpenAILLM(api_key=api_key)
    
    # Initialize Agents
    recon = ReconAgent(llm)
    vuln = VulnAnalysisAgent(llm)
    report = ReportAgent(llm)
    
    supervisor = SupervisorAgent(llm, [recon, vuln, report])
    
    # Initialize Context
    context = PentestContext(target=target, mode=mode)
    
    # Run Assessment
    final_context = supervisor.run(context)
    
    console.print("\n[bold green]Assessment Complete![/bold green]")
    console.print(f"Total Findings: {len(final_context.findings)}")
    console.print("Check the 'reports' directory for the final report.")

if __name__ == "__main__":
    app()
