"""Backward-compatible shim for planner/supervisor."""


class SupervisorAgent(BaseAgent):
    """High-level orchestrator for autonomous closed-loop assessment."""

    def __init__(
        self,
        llm: BaseLLM,
        agents: List[BaseAgent],
        max_cycles: int = 5,
        confidence_threshold: float = 0.8,
        coverage_threshold: float = 0.8,
        causal_threshold: float = 1.0,
        min_stable_cycles: int = 1,
    ):
        super().__init__("Supervisor", llm)
        self.agents = {agent.name: agent for agent in agents}
        self.max_cycles = max_cycles
        self.confidence_threshold = confidence_threshold
        self.coverage_threshold = coverage_threshold
        self.causal_threshold = causal_threshold
        self.min_stable_cycles = min_stable_cycles

    def _update_metrics(self, context: PentestContext, cycle: int, stable_cycles: int):
        findings = context.findings
        avg_confidence = sum([f.confidence for f in findings]) / len(findings) if findings else 0.0

        header_count = len(context.recon_data.get("raw", {}).get("headers", {}))
        surface_points = len(context.attack_surface.get("entry_points", [])) + len(context.attack_surface.get("exposed_services", []))
        coverage_score = min(1.0, (header_count / 12.0) + (len(findings) / 10.0) + (surface_points / 8.0))

        reachable = len([f for f in findings if f.reachable])
        analyzed = len([f for f in findings if f.reachable and f.analyzed])
        analyzed_ratio = round((analyzed / reachable), 3) if reachable else 1.0

        causal_completeness = float(context.attack_graph.get("causal_completeness", 0.0))

        context.assessment_metrics = {
            "cycle": cycle,
            "avg_confidence": round(avg_confidence, 3),
            "coverage_score": round(coverage_score, 3),
            "findings_count": len(findings),
            "reachable_findings": reachable,
            "analyzed_reachable_findings": analyzed,
            "analyzed_ratio": analyzed_ratio,
            "causal_completeness": causal_completeness,
            "stable_cycles_without_new_findings": stable_cycles,
            "confidence_threshold": self.confidence_threshold,
            "coverage_threshold": self.coverage_threshold,
            "causal_threshold": self.causal_threshold,
            "min_stable_cycles": self.min_stable_cycles,
        }

    def run(self, context: PentestContext) -> PentestContext:
        self.log(f"Starting autonomous closed-loop orchestration for {context.target}")

        workflow = [
            ("Reconnaissance", "ReconAgent"),
            ("Attack Surface Modeling", "AttackSurfaceAgent"),
            ("Vulnerability Analysis", "VulnAnalysisAgent"),
            ("Attack-Graph Reasoning", "ReasoningAgent"),
            ("Exploitability Analysis", "ExploitabilityAgent"),
            ("Risk Assessment", "RiskAgent"),
            ("Attack Simulation Planning", "AttackSimulationAgent"),
            ("Memory Update", "MemoryAgent"),
        ]

        stable_cycles = 0
        previous_count = 0

        with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}"), transient=True) as progress:
            for cycle in range(1, self.max_cycles + 1):
                self.log(f"Cycle {cycle}/{self.max_cycles} started")
                for description, agent_name in workflow:
                    if agent_name not in self.agents:
                        continue
                    task_id = progress.add_task(f"[cyan]Cycle {cycle}: {description}...", total=1)
                    try:
                        context = self.agents[agent_name].run(context)
                        progress.update(task_id, completed=1, description=f"[green]Cycle {cycle}: {description} Complete")
                    except Exception as e:
                        self.log(f"Error in {agent_name}: {str(e)}")
                        progress.update(task_id, completed=1, description=f"[red]Cycle {cycle}: {description} Failed")

                current_count = len(context.findings)
                stable_cycles = stable_cycles + 1 if current_count == previous_count else 0
                previous_count = current_count

                self._update_metrics(context, cycle, stable_cycles)
                m = context.assessment_metrics

                if (
                    m["avg_confidence"] >= self.confidence_threshold
                    and m["coverage_score"] >= self.coverage_threshold
                    and m["causal_completeness"] >= self.causal_threshold
                    and m["analyzed_ratio"] >= 1.0
                    and m["stable_cycles_without_new_findings"] >= self.min_stable_cycles
                ):
                    context.stop_reason = (
                        f"Stopped at cycle {cycle}: confidence/coverage/causal completeness met and all reachable findings analyzed "
                        f"(confidence={m['avg_confidence']}, coverage={m['coverage_score']}, causal={m['causal_completeness']}, analyzed={m['analyzed_reachable_findings']}/{m['reachable_findings']})."
                    )
                    break
            else:
                context.stop_reason = (
                    f"Stopped after max cycles ({self.max_cycles}) with best available evidence. "
                    "Run with higher --max-cycles if deeper exploration is required."
                )

        if "ReportAgent" in self.agents:
            context = self.agents["ReportAgent"].run(context)

        self.log(f"Pentest workflow completed. {context.stop_reason}")
        return context
